{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 1 - Algorithme de r√©tro-propagation de l‚Äôerreur\n",
    "\n",
    "**L‚Äôobjectif de cette premi√®re s√©ance de travaux pratiques est de vous faire impl√©menter par vous m√™me l‚Äôapprentissage de r√©seaux de neurones simples.**\n",
    "Cettre prise en main sera tr√®s formatrice pour utiliser des mod√®les plus √©volu√©s, et comprendre le fonctionnement des libaries (comme Keras) o√π l‚Äôapprentissage est automatis√©.\n",
    "\n",
    "On va travailler avec la base de donn√©es image MNIST, constitu√©e d‚Äôimages de\n",
    "caract√®res manuscrits (60000 images en apprentissage, 10000 en test).\n",
    "\n",
    "Voici un bout de code pour r√©cup√©rer les donn√©es  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 0 : visualisation de quelques images de la base\n",
    "<dl style='margin: 20px 0;'>\n",
    "<dt>Nous commencerons par afficher les 200 premi√®res images de la base d‚Äôapprentissage.</dt>\n",
    "<dd>\n",
    "    \n",
    "- √âcrire un script qui r√©cup√®re les donn√©es avec le code pr√©c√©dent.  \n",
    "- Compl√©ter pour permettre l‚Äôaffichage demand√© en utilisant le code suivant :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7.195, 3.841), dpi=100)\n",
    "for i in range(200):\n",
    "  plt.subplot(10,20,i+1)\n",
    "  plt.imshow(X_train[i,:].reshape([28,28]), cmap='gray')\n",
    "  plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question :\n",
    "\n",
    "Quel est l‚Äôespace dans lequel se trouvent les images ? Quel est sa taille ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : R√©gression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod√®le de pr√©diction\n",
    "\n",
    "\n",
    "<dl style='margin: 20px 0;'>\n",
    "<dt>On va d‚Äôabord commencer par cr√©er un mod√®le de classification lin√©aire populaire, la r√©gression logistique.</dt>\n",
    "<dd>\n",
    "Ce mod√®le correspond √† un r√©seau de neurones √† une seule couche, qui va projeter le vecteur d‚Äôentr√©e $ \\mathbf{x_i} $ pour une image MNIST\n",
    "(taille $ 28^2=784 $) avec un vecteur de de param√®tres $ \\mathbf{w_{c}} $ pour chaque classe (plus un biais $ b_c $).\n",
    "Pour correspondre √† la matrice des donn√©es de l‚Äôexercice pr√©c√©dent, on consid√®re que chaque exemple $ \\mathbf{x_i} $ est un vecteur ligne - taille (1,784).\n",
    "En regroupant l‚Äôensemble des jeux de param√®tres $ \\mathbf{w_{c}} $ pour les 10 classes dans une matrice $ \\mathbf{W} $ (taille $ 784\\times 10 $),\n",
    "et les biais dans un vecteur $ \\mathbf{b} $, on obtient un vecteur\n",
    "$ \\mathbf{\\hat{s_i}} =\\mathbf{x_i}  \\mathbf{W}  + \\mathbf{b} $ de taille (1,10).\n",
    "Une fonction d‚Äôactivation de type soft-max sur $ \\mathbf{\\hat{y_i}} = $ `softmax` $ (\\mathbf{s_i}) $ permet d‚Äôobtenir le vecteur de sortie pr√©dit par le mod√®le $ \\mathbf{\\hat{y_i}} $\n",
    "- de taille (1,10) - qui repr√©sente la probabilit√© *a posteriori*\n",
    "$ p(\\mathbf{\\hat{y_i}} | \\mathbf{x_i}) $ pour chacune des 10 classes:\n",
    "\n",
    "</dd>\n",
    "\n",
    "</dl>\n",
    "\n",
    "\n",
    "<a id='equation-softmax'></a>\n",
    "$$\n",
    "p(\\hat{y_{c,i}} | \\mathbf{x_i}) ) = \\frac{e^{\\langle \\mathbf{x_i} ; \\mathbf{w_{c}}\\rangle + b_{c}}}{\\sum\\limits_{c'=1}^{10} e^{\\langle \\mathbf{x_i} ; \\mathbf{w_{c'}}\\rangle + b_{c'}}} \\tag{1}\n",
    "$$\n",
    "\n",
    "Le sch√©ma ci-dessous illustre le mod√®le de r√©gression logistique avec un r√©seau de neurones.\n",
    "\n",
    "<img src=\"http://cedric.cnam.fr/~thomen/cours/US330X/_images/LR.png\" style=\"height:150px;\" align=\"center\">\n",
    "\n",
    "- Quel est le nombre de param√®tres du mod√®le ? Justifier le calcul.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulation du probl√®me d‚Äôapprentissage\n",
    "\n",
    "> Afin d‚Äôentra√Æner le r√©seau de neurones, on va comparer, pour chaque exemple d‚Äôapprentissage, la sortie pr√©dite $ \\mathbf{\\hat{y_i}} $ par le r√©seau\n",
    "(√©quation [(1)](#equation-softmax)) pour l‚Äôimage $ \\mathbf{x_i} $, avec la sortie\n",
    "r√©elle $ \\mathbf{y_i^*} $ issue de la supervision qui correspond √† la cat√©gorie de l‚Äôimage $ \\mathbf{x_i} $:\n",
    "on utilisera en encodage de type ¬´¬†one-hot¬†¬ª pour $ \\mathbf{y_i^*} $, *i.e.* :\n",
    "\n",
    "\n",
    "\n",
    "<a id='equation-one-hot'></a>\n",
    "$$\n",
    "y_{c,i}^* =\n",
    " \\begin{cases}\n",
    "   1 & \\text{si c correspond √† l'indice de la classe de } \\mathbf{x_i}  \\\\\n",
    "   0 & \\text{sinon}\n",
    " \\end{cases} \\tag{2}\n",
    "$$\n",
    "\n",
    "Pour mesurer l‚Äôerreur de pr√©diction, on utilisera une fonction de co√ªt de type entropie crois√©e (¬´¬†cross-entropy¬†¬ª) entre $ \\mathbf{\\hat{y_i}} $ et $ \\mathbf{y_i^*} $\n",
    "(l‚Äôentropie crois√©e est li√© √† la divergence de Kullback-Leiber, qui mesure une dissimilarit√© entre distributions de probabilit√©s) :\n",
    "$ \\mathcal{L}(\\mathbf{\\hat{y_i}}, \\mathbf{y_i^*}) = -\\sum\\limits_{c=1}^{10} y_{c,i}^* log(\\hat{y}_{c,i}) = - log(\\hat{y}_{c^*,i}) $, o√π $ c^* $ correspond √† l‚Äôindice de la classe donn√© par la supervision pour l‚Äôimage $ \\mathbf{x_i} $.\n",
    "\n",
    "La fonction de co√ªt finale consistera √† moyenner l‚Äôentropie crois√©e sur l‚Äôensemble de la base d‚Äôapprentissage $ \\mathcal{D} $ consistu√©e de $ N=60000 $ images :\n",
    "\n",
    "\n",
    "<a id='equation-ce'></a>\n",
    "$$\n",
    "\\mathcal{L}_{\\mathbf{W},\\mathbf{b}}(\\mathcal{D})  = - \\frac{1}{N}\\sum_{i=1}^{N} log(\\hat{y}_{c^*,i}) \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question :\n",
    "\n",
    "La fonction de co√ªt de l‚ÄôEq. [(3)](#equation-ce) est-elle convexe par rapports aux param√®tres $ \\mathbf{W} $, $ \\mathbf{b} $ du mod√®le ? Avec un pas de gradient bien choisi, peut-on assurer la convergence vers le minimum  global de la solution ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation du mod√®le\n",
    "\n",
    "Afin d‚Äôoptimiser les param√®tres $ \\mathbf{W} $ et $ \\mathbf{b} $ du mod√®le de r√©gression logistique par descente de gradient, on va utiliser la r√®gle des d√©riv√©es cha√Æn√©es (chain rule) :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} =  \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{\\hat{y_i}}}  \\frac{\\partial \\mathbf{\\hat{y_i}}}{\\partial \\mathbf{s_i}} \\frac{\\partial \\mathbf{s_i}}{\\partial \\mathbf{W}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}} =  \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{\\hat{y_i}}}  \\frac{\\partial \\mathbf{\\hat{y_i}}}{\\partial \\mathbf{s_i}} \\frac{\\partial \\mathbf{s_i}}{\\partial \\mathbf{b}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montrer que :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{s_i}} = \\mathbf{\\delta^y_i}  =\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{\\hat{y_i}}}  \\frac{\\partial \\mathbf{\\hat{y_i}}}{\\partial \\mathbf{s_i}} = \\mathbf{\\hat{y_i}} - \\mathbf{y_i^*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En d√©duire que les gradients de $ \\mathcal{L} $ par rapport aux param√®tres du mod√®le s‚Äô√©crivent :\n",
    "\n",
    "\n",
    "<a id='equation-gradientw-LR'></a>\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} = \\frac{1}{N} \\mathbf{X}^T (\\mathbf{\\hat{Y}} - \\mathbf{Y^*}) = \\frac{1}{N} \\mathbf{X}^T \\mathbf{\\Delta^y} \\tag{4}\n",
    "$$\n",
    "\n",
    "\n",
    "<a id='equation-gradientb-LR'></a>\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}} = \\frac{1}{N}\\sum_{i=1}^{N}(\\mathbf{\\hat{y_i}} - \\mathbf{y_i^*}) \\tag{5}\n",
    "$$\n",
    "\n",
    "O√π  $ \\mathbf{X} $ est la matrice des donn√©es (taille $ 60000\\times 784 $), $ \\mathbf{\\hat{Y}} $ est la matrice des labels pr√©dits sur l‚Äôensemble de la base d‚Äôapprentissage (taille $ 60000\\times 10 $)\n",
    "et $ \\mathbf{Y^*} $ est la matrice des labels donn√©e issue de la supervision (¬´¬†ground truth¬†¬ª, taille $ 60000\\times 10 $), et $ \\mathbf{\\Delta^y}=\\mathbf{\\hat{Y}}-\\mathbf{Y^*} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impl√©mentation de l‚Äôapprentissage\n",
    "\n",
    "Les gradients aux √©quations [(4)](#equation-gradientw-LR) et [(5)](#equation-gradientb-LR) s‚Äô√©crivent sous forme ¬´¬†vectorielle¬†¬ª, ce qui va rendre les calculs efficaces avec des librairies de calculs scientifique comme `numpy`. Apr√®s calcul du gradient, les param√®tres\n",
    "seront mis √† jour de la mani√®re suivante :\n",
    "\n",
    "\n",
    "<a id='equation-gradientupdatew'></a>\n",
    "$$\n",
    "\\mathbf{W}^{(t+1)} = \\mathbf{W}^{(t)} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} \\tag{6}\n",
    "$$\n",
    "\n",
    "\n",
    "<a id='equation-gradientupdateb'></a>\n",
    "$$\n",
    "\\mathbf{b}^{(t+1)} = \\mathbf{b}^{(t)} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}} \\tag{7}\n",
    "$$\n",
    "\n",
    "o√π $ \\eta $ est le pas de gradient (learning rate).\n",
    "\n",
    "Pour impl√©menter l‚Äôalgorithme d‚Äôapprentissage, on utuilisera une descente de gradient stochastique, c‚Äôest √† dire que les gradients aux √©quations [(4)](#equation-gradientw-LR) et [(5)](#equation-gradientb-LR)  ne seront pas calcul√©s\n",
    "sur l‚Äôensemble des $ N=60000 $ images d‚Äôapprentissage, mais sur un sous ensemble appel√© **batch**. Cette technique permet une mise √† jour des param√®tres plus fr√©quente qu‚Äôavec une descente de gradient classique, et une convergence\n",
    "plus rapide (au d√©triment d‚Äôun calcul de gradient approxim√©).\n",
    "\n",
    "**On demande de mettre en place un script** `exo1.py` **qui impl√©mente l‚Äôalogorithme de r√©gression logistique sur la base MNIST.**\n",
    "\n",
    "Apr√®s avoir charg√© les donn√©es (exercice 0), on utilisera le code suivant pour g√©n√©rer des labels au format\n",
    "0-1 encoding - √©quation [(2)](#equation-one-hot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "K=10\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, K)\n",
    "Y_test = np_utils.to_categorical(y_test, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On pourra utiliser la fonction suivante pour calculer la fonction softmax sur chaque √©l√©ment de de la matrice de la projection lin√©raire (taille ùë°ùëè√ó10) :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    # Input matrix X of size Nbxd - Output matrix of same size\n",
    "    E = np.exp(X)\n",
    "    return (E.T / np.sum(E,axis=1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On mettra alors en place un code dont le squellette est donn√© ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "N = X_train.shape[0]\n",
    "d = X_train.shape[1]\n",
    "W = np.zeros((d,K))\n",
    "b = np.zeros((1,K))\n",
    "numEp = 20 # Number of epochs for gradient descent\n",
    "eta = 1e-1 # Learning rate\n",
    "batch_size = 100\n",
    "nb_batches = int(float(N) / batch_size)\n",
    "gradW = np.zeros((d,K))\n",
    "gradb = np.zeros((1,K))\n",
    "\n",
    "for epoch in range(numEp):\n",
    "    for ex in range(nb_batches):\n",
    "        # FORWARD PASS : compute prediction with current params for examples in batch\n",
    "        # BACKWARD PASS :\n",
    "        # 1) compute gradients for W and b\n",
    "        # 2) update W and b parameters with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour compl√©ter ce code, vous devez :\n",
    "\n",
    "- Mettre en place une fonction `forward(batch, W, b)` qui va calculer la pr√©diction pour un batch de donn√©es. La fonction `forward` sera appel√©e pour chaque it√©ration de la double boucle pr√©c√©dente.  \n",
    "\n",
    "\n",
    "> - Si on consid√®re un batch des donn√©es de taille $ tb\\times 784 $, les param√®tres $ \\mathbf{W} $ (taille $ 784\\times 10 $) et $ \\mathbf{b} $ (taille $ 1\\times 10 $), la fonction `forward` renvoie la pr√©diction $ \\mathbf{\\hat{Y}} $ sur le batch (taille $ tb\\times 10 $).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compl√©ter le code pour la passe backward, consistant √†  :\n",
    "  - Calculer les gradient comme indiqu√© aux √©quations [(4)](#equation-gradientw-LR) et [(5)](#equation-gradientb-LR).\n",
    "  - Mettre √† jour les param√®tres par descente de gradient comme indiqu√© aux √©quations [(6)](#equation-gradientupdatew) et [(7)](#equation-gradientupdateb).  \n",
    "\n",
    "\n",
    "Enfin vous pouvez utiliser la fonction `accuracy(W, b, images, labels)` fournie pour calculer le taux de bonne reconnaissance du mod√®le. Ceci permettra de mesurer l‚Äô√©volution des performances au cours des √©poques de l‚Äôalgorithme d‚Äôapprentissage, et sur la base de test une fois le mod√®le appris.\n",
    "\n",
    "### Vous devez obtenir un score de l‚Äôordre de 92% sur la base de test pour ce mod√®le de r√©gression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def accuracy(W, b, images, labels):\n",
    "  pred = forward(images, W,b )\n",
    "  return np.where( pred.argmax(axis=1) != labels.argmax(axis=1) , 0.,1.).mean()*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Perceptron multi-couches (MLP)\n",
    "\n",
    "### L‚Äôobjectif de ce second exercice est d‚Äô√©tendre le mod√®le de r√©gression logistique afin de mettre en place des mod√®les de pr√©dictions plus riches.\n",
    "**En particulier, on va s‚Äôint√©resser aux Perceptron multi-couches (Multi-Layer Percpetron, MLP)**. Contrairement √† la r√©gression logistique qui se limite √† des s√©parateurs lin√©aires,\n",
    "le Perceptron permet l‚Äôapprentissage de fronti√®res de d√©cisions non lin√©aires, et constituent des approximateurs universels de fonctions.\n",
    "\n",
    "L‚Äôobjectif de la s√©ance de travaux pratiques est de mettre en place le code pour effectuer des pr√©dictions et entra√Æner un Perceptron √† une couche cach√©e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©diction avec un Perceptron (Forward)\n",
    "\n",
    "L‚Äôarchitecture du perpcetron √† une couche cach√©e est montr√©e √† la figure ci-dessous.\n",
    "\n",
    "<img src=\"http://cedric.cnam.fr/~thomen/cours/US330X/_images/MLP.png\" style=\"height:250px;\" align=\"center\">\n",
    "\n",
    "Si on consid√®re les donn√©es de la base MNIST, chaque image est repr√©sent√©e par un vecteur de taille $ 28^2=784 $.\n",
    "Le perpcetron va effecteur les diff√©rentes √©tape de transformation pour produire la pr√©diction finale, *i.e.* la cat√©gorie s√©mantique de l‚Äôimage :\n",
    "\n",
    "- Une √©tape de projection lin√©aire, qui va projeter chaque image sur un vecteur de taille $ (1,L) $, *e.g.* $ L=100 $. En consid√©rant chaque exemple $ \\mathbf{x_i} $ est un vecteur ligne - taille $ (1,784) $ - la projection lin√©aire peut √™tre repr√©sent√©e par la matrice $ \\mathbf{W^h} $ (taille $ (784, L) $), et le vecteur de biais $ \\mathbf{b^h} $ (taille $ (1, L) $) : $ \\mathbf{\\hat{u_i}} =\\mathbf{x_i}  \\mathbf{W^h}  + \\mathbf{b^h} $.  \n",
    "\n",
    "\n",
    "> - Une √©tape de non lin√©arit√©, *e.g.* de type sigmo√Øde :  $ \\forall j \\in  \\left\\lbrace 1; L \\right\\rbrace  ~ h_{i,j} = \\frac{1}{1+exp(-u_{i,j})} $  \n",
    "\n",
    "\n",
    "\n",
    "- Une seconde √©tape de projection lin√©aire, qui va projeter le vecteur latent de taille $ (1,L) $ sur un vecteur de taille $ (1,K)=10 $ (nombre de classes). Cette op√©ration de projection lin√©aire sera repr√©sent√©e par la matrice $ \\mathbf{W^y} $ (taille $ (L, K) $), et le vecteur de biais $ \\mathbf{b^y} $ (taille $ (1, K) $) : $ \\mathbf{\\hat{v_i}} =\\mathbf{h_i}  \\mathbf{W^y}  + \\mathbf{b^y} $.  \n",
    "\n",
    "\n",
    "> - Une √©tape de non lin√©arit√© de type soft-max vue la semaine pr√©c√©dente pour la r√©gression logistique : $ \\forall j \\in  \\left\\lbrace 1; K \\right\\rbrace  ~ y_{i,j} = \\frac{exp(v_{i,j})}{\\sum\\limits_{i=1}^K exp(v_{i,k})} $  \n",
    "\n",
    "\n",
    "\n",
    "**On demande de mettre en place un script** `mlp.py` **qui impl√©mente l‚Äôalogorithme du Percpetron sur la base MNIST.**\n",
    "\n",
    "\n",
    "<dl style='margin: 20px 0;'>\n",
    "<dt>L‚Äôalgorithme reprendra le squelette du code de la r√©gression logistique. Pour adapter ce code pour le Perceptron pour la partie pr√©diction,  vous devez :</dt>\n",
    "<dd>\n",
    "- Modifier la fonction de pr√©diction, afin disposer la fonction `forward(batch, Wh, bh, Wy, by)` qui reverra √† la fois la pr√©diction pour le batch ainsi que la matrice des couches latentes.  \n",
    "\n",
    "\n",
    "> - Si on consid√®re un batch des donn√©es de taille $ t_b\\times 784 $, les param√®tres $ \\mathbf{W^h} $ (taille $ 784\\times L $), $ \\mathbf{b^h} $ (taille $ 1\\times L $), $ \\mathbf{W^y} $ (taille $ L\\times K $) et $ \\mathbf{b^y} $ (taille $ 1\\times K $), la fonction `forward` renvoie la pr√©diction $ \\mathbf{\\hat{Y}} $ sur le batch (taille $ t_b\\times K $) et la matrice de variables latentes (taille $ t_b\\times L $).  \n",
    "\n",
    "\n",
    "\n",
    "</dd>\n",
    "\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function forward pour le MLP\n",
    "def forward(batch, Wh, bh, Wy, by):                 \n",
    "    latent = 0\n",
    "    res = 0\n",
    "    return latent, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'accuracy avec le MLP\n",
    "def accuracy(batch, labels,Wh, bh, Wy, by):\n",
    "   latent, pred = forward(batch, Wh, bh, Wy, by)  \n",
    "   return np.where( pred.argmax(axis=1) != labels.argmax(axis=1) , 0.,1.).mean()*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apprentissage du Perceptron (Backward)\n",
    "\n",
    "Afin d‚Äôentra√Æner le Perceptron, on va utiliser l‚Äôalgorithme de r√©tro-propagation de l‚Äôerreur. On rappelle que pour chaque batch d‚Äôexemples, l‚Äôalgorithme va effectuer une passe `forward` (Exercice 1), permettant de calculer la pr√©diction du r√©seau.\n",
    "Une fonction de co√ªt (ici l‚Äôentropie crois√©e) entre la sortie pr√©dite et la la sortie donn√©e par la supervision va permettre de calculer le gradient de l‚Äôerreur par rapport √† tous les param√®tres param√®tres du mod√®le, *i.e.* $ \\mathbf{W^y} $ (taille $ (L, K) $), $ \\mathbf{b^y} $ (taille $ (1, K) $), $ \\mathbf{W^h} $ (taille $ (784, L) $), et $ \\mathbf{b^h} $ (taille $ (1, L) $).\n",
    "\n",
    "On rappelle les √©quation des gradients, effectu√©es depuis le haut vers le bas du r√©seau :\n",
    "\n",
    "1. Mise √† jour de $ \\mathbf{W^y} $ et $ \\mathbf{b^y} $ :  \n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{v_i}} = \\mathbf{\\delta^y_i} = \\mathbf{\\hat{y_i}} - \\mathbf{y_i^*}\n",
    "$$\n",
    "\n",
    "\n",
    "<a id='equation-gradientw'></a>\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W^y}} = \\frac{1}{t_b}\\mathbf{H}^T (\\mathbf{\\hat{Y}} - \\mathbf{Y^*}) = \\frac{1}{t_b} \\mathbf{H}^T \\mathbf{\\Delta^y} \\tag{8}\n",
    "$$\n",
    "\n",
    "\n",
    "<a id='equation-gradientb'></a>\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b^y}} = \\frac{1}{t_b}\\sum_{i=1}^{t_b}(\\mathbf{\\hat{y_i}} - \\mathbf{y_i^*}) \\tag{9}\n",
    "$$\n",
    "\n",
    "O√π  $ \\mathbf{H} $ est la matrice des couches cach√©es sur le batch (taille $ t_b\\times L $), $ \\mathbf{\\hat{Y}} $ est la matrice des labels pr√©dits sur l‚Äôensemble de la base d‚Äôapprentissage (taille $ t_b\\times K $)\n",
    "et $ \\mathbf{Y^*} $ est la matrice des labels donn√©e issue de la supervision (¬´¬†ground truth¬†¬ª, taille $ t_b\\times K $), et $ \\mathbf{\\Delta^y}=\\mathbf{\\hat{Y}}-\\mathbf{Y^*} $.\n",
    "\n",
    "1. Mise √† jour de $ \\mathbf{W^h} $ et $ \\mathbf{b^h} $ :  \n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{u_i}} = \\mathbf{\\delta^h_i} = \\mathbf{\\delta^y_i} \\mathbf{W^{y}}^T   \\odot \\sigma^{'}(\\mathbf{u_i}) = \\mathbf{\\delta^y_i} \\mathbf{W^{y}}^T \\odot (\\mathbf{h_i} \\odot (1-\\mathbf{h_i}))\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W^h}} =  \\frac{1}{t_b} \\mathbf{X}^T \\mathbf{\\Delta^h}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b^h}} = \\frac{1}{t_b}\\sum_{i=1}^{t_b}(\\delta^h_i)\n",
    "$$\n",
    "\n",
    "O√π  $ \\mathbf{X} $ est la matrice des donn√©es sur le batch (taille $ t_b\\times 784 $), et $ \\mathbf{\\Delta^h} $ est la matrice des $ \\delta^h_i $ sur le batch (taille $ t_b\\times L $)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapter la partie backward de l‚Äôalgorithme pour entra√Æner le Perceptron.\n",
    "On Choisira un pas de gradient $ \\eta=1.0 $ et 100 √©poques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = X_train.shape[1] # dimension d'entr√©e (784)\n",
    "N = X_train.shape[0] # nombre d'exemples d'apprentissage (60000)\n",
    "L=100 # dimension de l'espace latent \n",
    "\n",
    "# Initialisation des poids : Gaussienne ou Glorot (voir ci-dessous)  \n",
    "Wh = 0\n",
    "bh = 0\n",
    "Wy = 0\n",
    "by = 0\n",
    "\n",
    "# Hyper-param√®tres d'apprentissage\n",
    "numEpochs = 50\n",
    "eta = 1\n",
    "\n",
    "batch_size = 100\n",
    "nb_batches = int(float(N) / batch_size)\n",
    "\n",
    "for it in range(numEpochs):\n",
    "    for b in range(nb_batches):\n",
    "        # FORWARD\n",
    "        \n",
    "        # BACKWARD \n",
    "        # Calcul de deltay = dE / dy~         \n",
    "        # Calcul de gradWy = h^T * deltay - (LxN) * (NxK)  et gradby      \n",
    " \n",
    "        # Calcul de  deltah   =dE / dh~ size (N,L)\n",
    "        # Calcul de gradWh = x^T * deltah - (dxN) * (NxL) = (dxL) et gradbh\n",
    "        \n",
    "        # Mise √† jour des poids du r√©seau\n",
    "    \n",
    "    print(\"epoch \", it, \"accurcy train=\",accuracy(X_train, Y_train, Wh, bh, Wy, by), \"accurcy test=\",accuracy(X_test, Y_test, Wh, bh, Wy, by))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions :\n",
    "\n",
    "- La fonction de co√ªt de l‚ÄôEq. [(3)](tpDeepLearning1.ipynb#equation-ce) est-elle convexe par rapport aux param√®tres $ \\mathbf{W} $, $ \\mathbf{b} $ du mod√®le ? Avec un pas de gradient bien choisi, peut-on assurer la convergence vers le minimum global de la solution ?  \n",
    "- Tester en initialisant les matrices √† 0 comme pour la r√©gression logistique. Quelles performances obtenez-vous ? Que peut-on en conclure ?  \n",
    "- Vous testerez deux autres initialisations : une qui initialise les poids avec une loi normale de moyenne nulle et d‚Äô√©cart type √† fixer, *e.g.* $ 10^-1 $, et une autre connue sous le nom de Xavier [[GB10]](#glorot10understandingthe), qui divise la valeur de la gaussienne par $ \\sqrt{ni} $, o√π $ ni $ est le nombre de neurone dans la couche d‚Äôentr√©e.  \n",
    "- √âvaluer les performances du mod√®le. **Vous devez obtenir un score de l‚Äôordre de 98% sur la base de test pour ce r√©seau de neurones √† une couche cach√©e.**  \n",
    "\n",
    "\n",
    "<a id='glorot10understandingthe'></a>\n",
    "\\[GB10\\] Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In *In Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS‚Äô10). Society for Artificial Intelligence and Statistics*. 2010."
   ]
  }
 ],
 "metadata": {
  "date": 1637163670.9135308,
  "filename": "tpbackprop.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "title": "TP 1 - Algorithme de r√©tro-propagation de l‚Äôerreur"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
